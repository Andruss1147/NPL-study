## Лаба 10. Построить рекомендательную систему видеоконтента с implicit feedback

<img width="350px" src="images/megafon_logo.jpg">

##### Лаба создана при поддержке компании «МегаФон». 

##### [![New Professions Lab — Big Data 8](http://data.newprolab.com/public-newprolab-com/npl7.svg)](https://github.com/newprolab/content_bigdata8)

### Дедлайн

⏰ Понедельник, 12 июня 2018 года, 23:59.

### Задача

В вашем распоряжении имеется уже предобработанный и очищенный датасет с фактами
покупок абонентами телепередач от компании E-Contenta. По доступным вам данным нужно предсказать вероятность покупки других передач этими, а, возможно, и другими абонентами.

### Обработка данных на вход

Для выполнения работы вам следует взять все файлы из папки на HDFS `/labs/lab10data/`. Давайте посмотрим, что у нас есть:

```
$ hadoop fs -ls /labs/lab10data
Found 4 items
-rw-r--r--   3 hdfs hdfs   91066524 2017-05-09 13:51 /labs/lab10data/lab10_items.csv
-rw-r--r--   3 hdfs hdfs   29965581 2017-05-09 13:50 /labs/lab10data/lab10_test.csv
-rw-r--r--   3 hdfs hdfs   74949368 2017-05-09 13:50 /labs/lab10data/lab10_train.csv
-rw-r--r--   3 hdfs hdfs  871302535 2017-05-09 13:51 /labs/lab10data/lab10_views_programmes.csv
```

* В `lab10_train.csv` содержатся факты покупки (колонка `purchase`) пользователями (колонка `user_id`) телепередач (колонка `item_id`). Такой формат файла вам уже знаком.

* `lab10_items.csv` — дополнительные данные по items. В данном файле много лишней или ненужной информации, так что задача её фильтрации и отбора ложится на вас. Поля в файле, на которых хотелось бы остановиться:
  * `item_id` — primary key. Соответствует `item_id` в предыдущем файле.
  * `content_type` — тип телепередачи (`1` — платная, `0` — бесплатная). Вас интересуют платные передачи.
  * `title` — название передачи, текстовое поле.
  * `year` — год выпуска передачи, число.
  * `genres` — поле с жанрами передачи, разделёнными через запятую.
* `lab10_test.csv` — тестовый датасет без указанного целевого признака `purchase`, который вам и предстоит предсказать.
* Дополнительный файл `lab10_views_programmes.csv` по просмотрам передач с полями:
  * `ts_start` — время начала просмотра
  * `ts_end` — время окончания просмотра
  * `item_type`— тип просматриваемого контента:
    * `live` — просмотр "вживую", в момент показа контента в эфире
    * `pvr` — просмотр в записи, после показа контента в эфире


### Обработка данных на выход

Предсказание целевой переменной "купит/не купит" — хорошо знакомая вам задача бинарной классификации, с которой вы уже встречались в [Лабе 4](labs/lab04/lab04.md). Поскольку нам важны именно вероятности отнесения пары `(пользователь, товар)` к классу "купит" (`1`), то, на самом деле, вы можете подойти к проблеме с разных сторон:
1. Как к разработке рекомендательной системы: рекомендовать пользователю `user_id` топ-N лучших телепередач, которые были найдены по методике user-user / item-item коллаборативной фильтрации.
2. Как к задаче факторизации матриц: алгоритмы SVD, ALS, FM/FFM.
3. Как просто к задаче бинарной классификации. У вас есть два датасета, которые можно каким-то образом объединить, дополнительно обработать и сделать предсказания классификаторами (Apache Spark, pandas + sklearn на ваше усмотрение).
4. Как к задаче регрессии. Поскольку от вас требуется предсказать не факт покупки, а его *вероятность*, то можно перевести задачу в регрессионную и решать её соответствующим образом. 

### Подсказки

1. Кроссвалидация — ваш друг. Используйте `pyspark.ml.tuning.TrainValidationSplit` вместе с `ParamGridBuilder`, чтобы произвести grid search гиперпараметров вашей модели.
2. Простой подсчёт ROC AUC в Apache Spark доступен в `pyspark.ml.evaluation.BinaryClassificationEvaluator`.

### Проверка

Мы будем оценивать ваш алгоритм по метрике ROC AUC. Ещё раз напомним, что чекеру требуются *вероятности* в диапазоне `[0.0, 1.0]` отнесения пары `(пользователь, товар)` в тестовой выборке к классу "1" (купит).

Для успешного прохождения лабораторной работы **AUC должен составить не менее 0.6**.

**Важно!** Для точной проверки не забудьте отсортировать полученный файл по возрастанию идентификаторов пользователей (`user_id`), а затем — по возрастанию идентификаторов передач (`item_id`).

Результат следует сохранить в файл `lab10.csv` в своей домашней директории.

Проверка осуществляется [автоматическим скриптом](http://lk.newprolab.com/lab/laba10) из Личного кабинета.
