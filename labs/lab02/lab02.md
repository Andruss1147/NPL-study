## Лаба 2. Загрузить данные в HBase из большого лог-файла, лежащего в HDFS с помощью MapReduce

##### [![New Professions Lab — Big Data 8](http://data.newprolab.com/public-newprolab-com/npl7.svg)](https://github.com/newprolab/content_bigdata8)

### Дедлайн

⏰ Воскресенье, 8 апреля 2018 года, 23:59.


### Задача
Вы разрабатываете новую рекламную кампанию и хотите среди всех пользователей выбрать только тех, кто соответствует определенной категории интересов. UID пользователя в данных генерировался не случайно, а в него закладывалась информация о категории интереса пользователя.

Для решения задачи вам нужно загрузить данные из кластерного HDFS в HBase при помощи MapReduce, осуществив предварительную фильтрацию данных.

##### Напомним несколько полезных вещей:

Можно просмотреть содержимое директорий:
`hadoop fs -ls /`

Просмотреть содержимое файлов (первые 100 строк файла `part-00000`):

`hadoop fs -cat /labs/facetz_2015_02_01/part-00000 | head -n100`

Скачать файл с HDFS на локальную машину:

`hadoop fs -get /labs/facetz_2015_02_01/part-00000`


#### Веб-интерфейс кластера

Для вас поднят Hadoop-кластер (включая HDFS/HBase/YARN), ресурсы которого вы можете посмотреть через Ambari.

Веб-интерфейс Ambari доступен по адресу: http://master.nplcloud.com:8080/

Доступ к кластерному Ambari — по логину/паролю `guest / Newprolab2017`.

В состав кластера входят 6 узлов, один из которых предназначен для запуска MapReduce-задач, а остальные являются рабочими нодами для выполнения вычислений (хотя это не единственная их функция). Рекомендуем сразу зайти в список хостов и посмотреть, какие сервисы находятся на каждом из них: http://master.nplcloud.com:8080/#/main/hosts — например, можете сами определить, к какому хосту нужно подключаться для доступа к Thrift-интерфейсу HBase (к любому node).

#### Подключение к гейтвею кластера по SSH
У вас теперь один общий кластер с хостнеймом `master.nplcloud.com`. Доступ к кластеру осуществляется по адресу и ключу, которые можно взять на странице Личного кабинета (тот же, что в предыдущей лабе), а в качестве логина использовать логин к Личному кабинету.

Пример:

`ssh -i npl.pem john.smith@master.nplcloud.com`

Мы снова, как и в Лабе #1, рекомендуем вам прописать профиль подключения к кластеру в `~/.ssh/config`, чтобы подключаться к гейтвею кластера без лишних сложностей. Гейтвей `master.nplcloud.com` будет вашей дефолтной машиной для работы через ssh до конца курса.

#### Структура данных facetz на HDFS

Ваш пользователь на кластере уже имеет все необходимые права и доступы к бинарникам, позволяющим работать с HDFS, поэтому логиниться под `hdfs` не нужно.

Исходные файлы расположены **в HDFS** общего кластера в директориях по адресу 
`/labs/facetz_YYYY_MM_DD/`, где YYYY_MM_DD - дата. 
В директориях расположены файлы вида `part-NNNNN`, где `NNNNN` - порядковый номер файла.

Каждый файл представляет собой коллекцию записей, по записи на строчку, где каждая строка представляет собой кортеж `(UID, timestamp, URL)`.
* `UID` — уникальный идентификатор пользователя, представленный натуральным числом, записанным в десятичной форме. 
* `timestamp` — отметка времени, записанная в форме UNIX timestamp, записана в виде десятичной дроби. 
* `URL` — экранированный URL, представлен в виде строки. 
* Записи разделены символом табуляции `\t`.

Пример:

`26153949061	1422751272.768	http%3A%2F%2Frzd.ru%2F`

#### Обработка данных на вход
Для выполнения работы вам следует **взять все файлы** из директории, которая указана в [Личном кабинете](http://lk.newprolab.com/lab/lab02).

⚠️ Замечание: неправильно сформированные строки следует игнорировать.
Неправильные строки — строки, в которых нет хотя бы одного из трёх элементов, в `URL` или в `UID` указан прочерк, или, вообще, неверный формат. URL должны начинаться с http.

Вам необходимо оставить только те строки, для которых выполняется индивидуальное условие: `UID mod 256 == N`, где N берётся из [Личного кабинета](http://lk.newprolab.com/lab/lab02).

URL не нужно нормализовывать, вообще никак преобразовывать.

#### Обработка данных на выход
⚠️ Важно: Название таблицы, которую вам необходимо заполнить, должно совпадать с логином ЛК.

⚠️ Важно: Если вы собираетесь что-то заливать в HDFS, пожалуйста, делайте это в своей HDFS-директории: `/user/[ваше-имя-пользователя]`

В нашем примере таблица должна называться `john.smith`, для каждой записи должно храниться 4096 версий.

Содержимое таблицы должно представлять собой rowkey=`uid` и column=`data:url`. Отметка времени в базе должна совпадать с отметкой в файле, а не с моментом, когда запись попала в базу. 

❗️**Обратите внимание:** отметку надо умножить на 1000 и привести к int: `int(ts * 1000)`.

#### Подсказки и советы
**[1]** Для загрузки данных из python предлагаем воспользоваться библиотекой Happybase (http://happybase.readthedocs.org/en/latest/).

Подключаться с помощью `happybase` нужно к хосту `node3.nplcloud.com` или другому node. Пример создания соединения в python:

```
import happybase
connection = happybase.Connection('node3.nplcloud.com')
```

**[2]** Сначала напишите программу которая принимает на stdin файл и складывает его в вашу базу в HBase. Если локально отработает — запускайте на hadoop.

**[3]** Чтобы не прописывать постоянно длинный путь к jar-файлу для запуска hadoop-streaming, скопируйте его себе в домашнюю директорию:

`cp /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar ~/hadoop-streaming.jar`

или сделайте символическую ссылку:

`ln -s /usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar ~/hadoop-streaming.jar`

Тогда вы сможете в команде писать только: `~/hadoop-streaming.jar`

**[4]** В первой строчке исполняемого python-файла нужно прописать путь к интерпретатору `#!/usr/bin/env python3`, тогда в самой команде запуска `hadoop-streaming` не придётся прописывать, чем открывать файл.

**[5]** Если у вас MapReduce job выдаёт ошибки, то для дебага воспользуйтесь http-ссылкой на статус джобы. Её можно найти в логе инициализации джобы, который выводится вам в консоль:

```
17/03/10 15:14:42 INFO impl.YarnClientImpl: Submitted application application_1488372559028_0002
17/03/10 15:14:42 INFO mapreduce.Job: The url to track the job: http://node1.newprolab.com:8088/proxy/application_1488372559028_0002/
```

В веб-интерфейсе нажмите на ссылку "logs", по которой вы получите достаточно логов (в том числе, stderr-вывод python-скрипта, в котором у вас наверняка и есть ошибка):

```
Log Type: stderr
Log Upload Time: Fri Mar 10 15:15:45 +0300 2017
Log Length: 498
Traceback (most recent call last):
  File "/disk1/hadoop/yarn/local/usercache/hdfs/appcache/application_1488372559028_0002/container_e01_1488372559028_0002_01_000034/./m.py", line 4, in <module>
    import happybase
ImportError: No module named happybase
```

**[6]** У HBase есть веб-интерфейс: http://master.nplcloud.com:16010/master-status. Здесь вы, например, можете посмотреть, какие таблицы созданы и есть ли среди них ваша.

#### Проверка
Проверка осуществляется автоматическим скриптом из личного кабинета. В личном кабинете существует раздел “Результаты”. Там можно будет увидеть результаты всех пройденных лаб, начиная с этой.
